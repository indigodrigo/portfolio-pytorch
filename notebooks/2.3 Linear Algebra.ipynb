{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd55c3a-f269-4a26-b22b-936cc6c527a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x+y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd8204b-3ed8-45c8-9580-63abd73eeb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f485eba-c7c4-4d24-bf1d-fb49d8ba2b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8507f4-6ceb-42e7-97ba-d4ac221fba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 3.],\n",
       "         [5., 4., 5.]],\n",
       "\n",
       "        [[6., 7., 6.],\n",
       "         [8., 9., 8.]],\n",
       "\n",
       "        [[3., 2., 3.],\n",
       "         [5., 4., 5.]],\n",
       "\n",
       "        [[6., 7., 6.],\n",
       "         [8., 9., 8.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]],[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]]]) #tensor 3D\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0233483-5c63-40d4-b0f4-cf978b0b210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#o tensor é composto por matrizes.\n",
    "print(len(x)) #comprimento da dimensão\n",
    "print(x.shape) #4 -> quatro matrizes que compoem o tensor(dimensao0)\n",
    "               #2 -> duas linhas em cada matriz(dimensao1)\n",
    "               #3 -> três colunas em cada(dimensao2)\n",
    "\n",
    "#o número de elementos em torch.Size([]) define se o vetor é 1D, 2D, 3D, 4D, etc...\n",
    "#x.shape retorna torch.Size([dimensão0, dimensão1, dimensão2, dimensão3,..., etc.]). Num tensor 3D, a dimensão 0 seria a quantidade de matrizes 2D. \n",
    "#Um tensor 2D é uma matriz, e a dimensão 0 será o número de linhas desta matriz. Um tensor 1D é um vetor, e a dimensão 0 será o número de elementos. \n",
    "#Num tensor 4D, dimensão 0 seria a quantidade de matrizes 3D que o compõem.\n",
    "# a visualização de cubos não funciona muito bem para tensores. é melhor visualizar cada matriz 2D que compõe um tensor 3D\n",
    "#como uma camada (2D) numa pilha de camadas\n",
    "#len() retorna o comprimento da dimensão0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f3ff28-283d-425b-8a6b-ca5d1664095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2., 3.],\n",
       "        [5., 4., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[3.0,2.0,3.0],[5.0,4.0,5.0]]) #tensor 2D\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e710b2-2d63-4a0b-a6c8-81606a921f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(x)) #como há apenas uma matriz (tensor 2D), ao inves de retornar o numero de matrizes no tensor, retorna o número de linhas no tensor\n",
    "print(x.shape) #só há um vetor no tensor(tensor 2D), e a dimensao0 é o número de linhas presente no tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492a92c4-a464-4724-9407-f7c0e0537230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 3.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3.0,2.0,3.0]) #tensor 1D\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7f3018-2083-4e57-ba20-dbe12d579926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f612d6a2-3770-4e81-bf3d-906b99347c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]],\n",
      "\n",
      "         [[ 5.,  6.],\n",
      "          [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "        [[[ 9., 10.],\n",
      "          [11., 12.]],\n",
      "\n",
      "         [[13., 14.],\n",
      "          [15., 16.]]]])\n",
      "torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_4d = torch.tensor([\n",
    "    [  # Primeiro \"bloco\" da Dimensão 0\n",
    "        [  # Primeira \"matriz\" da Dimensão 1\n",
    "            [1.0, 2.0],  # Primeira \"linha\" da Dimensão 2\n",
    "            [3.0, 4.0]   # Segunda \"linha\" da Dimensão 2\n",
    "        ],\n",
    "        [  # Segunda \"matriz\" da Dimensão 1\n",
    "            [5.0, 6.0],\n",
    "            [7.0, 8.0]\n",
    "        ]\n",
    "    ],\n",
    "    [  # Segundo \"bloco\" da Dimensão 0\n",
    "        [  # Primeira \"matriz\" da Dimensão 1\n",
    "            [9.0, 10.0],\n",
    "            [11.0, 12.0]\n",
    "        ],\n",
    "        [  # Segunda \"matriz\" da Dimensão 1\n",
    "            [13.0, 14.0],\n",
    "            [15.0, 16.0]\n",
    "        ]\n",
    "    ]\n",
    "])\n",
    "\n",
    "print(tensor_4d)\n",
    "print(tensor_4d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a34bf0-3639-4d5e-b7fa-04215f27fa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6) #tensor 1D (vetor)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5402503-8f3f-4c10-8b62-1a232c654083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A.reshape(3,2) #transformou tensor 1D (vetor) em tensor 2D (matriz)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d28fd401-d303-409f-b000-ff3316c33fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T #transpõe a matriz (linhas viram colunas e vice-versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72792900-1d4c-4a06-ab50-7653d58cb533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) #Matrizes quadradas que são iguais às suas transpostas são matrizes simetricas\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "520d15ef-6469-49ff-9f99-87287b62056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7]],\n",
       "\n",
       "        [[ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(3, 2, 4) #transformou tensor 1D em tensor 3D. Esse tensor 3D poderia representar uma imagem de 2px de altura e 4px de largura, e \n",
    "                                  #com 3 canais, um para vermelho(R), outro para verde(G), e outro para azul (B). Cada número está na\n",
    "                                  #localização de um pixel, e seu valor representa o valor (intensidade) do canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63113de-c60f-4af5-b4e6-afa5f7f5c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       "\n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]],\n",
       "\n",
       "         [[ 8,  9],\n",
       "          [10, 11]]],\n",
       "\n",
       "\n",
       "        [[[12, 13],\n",
       "          [14, 15]],\n",
       "\n",
       "         [[16, 17],\n",
       "          [18, 19]],\n",
       "\n",
       "         [[20, 21],\n",
       "          [22, 23]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 2, 2) #transformou tensor 1D em tensor 4D. #este tensor 4D poderia representar uma coleção de duas imagens,\n",
    "                                     #cada uma delas com dimensão 2x2 px e 3 canais de cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bbc3d6-56ed-488b-ac2d-e5b2c371e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scalars, vectors, matrices, and higher-order tensors all have some handy properties. For example, elementwise operations produce\n",
    "#outputs that have the same shape as their operands.\n",
    "\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46ebd97f-ce01-43d0-92ed-1b1708078f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e571d1b9-b5cb-4227-8770-ac30a8b5bafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " tensor([[[ 0,  2,  4,  6],\n",
       "          [ 8, 10, 12, 14],\n",
       "          [16, 18, 20, 22]],\n",
       " \n",
       "         [[24, 26, 28, 30],\n",
       "          [32, 34, 36, 38],\n",
       "          [40, 42, 44, 46]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding or multiplying a scalar and a tensor produces a result with the same shape as the original tensor.\n",
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "X, a + X, (a*X), (a * X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa9e8768-7f51-4167-afea-cc00ed74b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum() #x.sum()calcula a soma dos elementos do vetor (tensor 1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106ec761-79e9-4630-abf8-f1c7c519ab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor(15.))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.shape, A.sum() #no caso de tensores de dimensões arbitrárias, .sum() soma normalmente elemento por elemento em cada coluna/linha, retorna escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d6afeb7-360a-4435-9c0f-ffadefde4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]],\n",
       " \n",
       "         [[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]]]),\n",
       " torch.Size([4, 2, 3]),\n",
       " tensor(132.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]],[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]]])\n",
    "x, x.shape, x.sum() # novamente, soma-se elemento por elemento, chegando no resultado final de 132 e retorna escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a929d82-d37e-451c-a6fc-2552c35d1775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([3., 5., 7.]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.shape, A.sum(axis=0), A.sum(axis=0).shape #especificar o axis=0 faz com que as some-se apenas ao longo do eixo 0 (dimensão 0),\n",
    "                                               #que, neste caso (tensor 2D), engloba as duas linhas. Então soma-se um elemento de cada linha.\n",
    "                                               #0+3, 1+4, 2+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d2f0623-9f69-4baf-b03b-219bce1ab327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]],\n",
       " \n",
       "         [[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]]]),\n",
       " torch.Size([4, 2, 3]),\n",
       " tensor([[18., 18., 18.],\n",
       "         [26., 26., 26.]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape, x.sum(axis=0), x.sum(axis=0).shape #soma-se ao longo do eixo 0 (dimensão 0). Neste caso (tensor 3D), a dimensão 0\n",
    "                                               #engloba cada uma das matrizes 2D, então soma-se um elemento de cada matriz:\n",
    "                                               #Posição [0, 0] do resultado: 3.0 + 6.0 + 3.0 + 6.0 = 18.0\n",
    "                                               #Posição [0, 1] do resultado: 2.0 + 7.0 + 2.0 + 7.0 = 18.0\n",
    "                                               #Posição [0, 2] do resultado: 3.0 + 6.0 + 3.0 + 6.0 = 18.0\n",
    "                                               #Posição [1, 0] do resultado: 5.0 + 8.0 + 5.0 + 8.0 = 26.0\n",
    "                                               #Posição [1, 1] do resultado: 4.0 + 9.0 + 4.0 + 9.0 = 26.0\n",
    "                                               #Posição [1, 2] do resultado: 5.0 + 8.0 + 5.0 + 8.0 = 26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f961f78-9567-4f65-bd0b-688dd2cc4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0,  1],\n",
       "           [ 2,  3]],\n",
       " \n",
       "          [[ 4,  5],\n",
       "           [ 6,  7]],\n",
       " \n",
       "          [[ 8,  9],\n",
       "           [10, 11]]],\n",
       " \n",
       " \n",
       "         [[[12, 13],\n",
       "           [14, 15]],\n",
       " \n",
       "          [[16, 17],\n",
       "           [18, 19]],\n",
       " \n",
       "          [[20, 21],\n",
       "           [22, 23]]]]),\n",
       " torch.Size([2, 3, 2, 2]),\n",
       " tensor([[[12, 14],\n",
       "          [16, 18]],\n",
       " \n",
       "         [[20, 22],\n",
       "          [24, 26]],\n",
       " \n",
       "         [[28, 30],\n",
       "          [32, 34]]]),\n",
       " torch.Size([3, 2, 2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24).reshape(2, 3, 2, 2)\n",
    "x, x.shape, x.sum(axis=0), x.sum(axis=0).shape #neste caso (tensor 4D), a dimensão 0 engloba as \"coleções\", então soma-se um elemento de cada \"coleção\"\n",
    "                                               #0+12, 1+13, 2+14, 3+15, 4+16....etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b537fa48-4d93-40c5-953c-3ff39d9e05bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([ 3., 12.]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.shape, A.sum(axis=1), A.sum(axis=1).shape #especificar o axis=1 faz com que as some-se apenas ao longo do eixo 1 (dimensão 1),\n",
    "                                               #que, neste caso (tensor 2D), engloba as três colunas. Então soma-se um elemento de cada coluna.\n",
    "                                               #0+1+2, 3+4+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48cb74d9-af2e-4b2c-b281-9230608bd635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]],\n",
       " \n",
       "         [[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]]]),\n",
       " torch.Size([4, 2, 3]),\n",
       " tensor([[ 8.,  6.,  8.],\n",
       "         [14., 16., 14.],\n",
       "         [ 8.,  6.,  8.],\n",
       "         [14., 16., 14.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]],[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]]])\n",
    "x, x.shape, x.sum(axis=1), x.sum(axis=1).shape #soma-se ao longo do eixo 1 (dimensão 1). Neste caso (tensor 3D), a dimensão 1\n",
    "                                               #engloba as linhas das matrizes 2D, então soma-se um elemento de cada linha:\n",
    "                                               #Posição [0, 0] do resultado: 3.0 + 5.0 = 8.0\n",
    "                                               #Posição [0, 1] do resultado: 2.0 + 4.0 = 6.0\n",
    "                                               #Posição [0, 2] do resultado: 3.0 + 5.0 = 8.0\n",
    "                                               #Posição [1, 0] do resultado: 6.0 + 8.0 = 14.0\n",
    "                                               #Posição [1, 1] do resultado: 7.0 + 9.0 = 16.0\n",
    "                                               #Posição [1, 2] do resultado: 6.0 + 8.0 = 14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da56ef5c-d8ae-42e2-b1eb-e3561e651fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]],\n",
       " \n",
       "         [[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]]]),\n",
       " torch.Size([4, 2, 3]),\n",
       " tensor([[ 8.,  6.,  8.],\n",
       "         [14., 16., 14.],\n",
       "         [ 8.,  6.,  8.],\n",
       "         [14., 16., 14.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape, x.sum(axis=1), x.sum(axis=1).shape #neste caso (tensor 4D), a dimensão 1 engloba os tensores de cada \"coleção\", então soma-se um elemento de\n",
    "                                               #cada tensor\n",
    "                                               #0+4+8, 1+5+9, 2+6+10, 3+7+11, 12+16+20....etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b10f72-daaa-41c0-9d81-0573aa72f099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()  #Somar ao longo das linhas e colunas é o mesmo que utilizar A.sum(). Retorna escalar. \n",
    "                               #Mais especificamente, se o tensor possui apenas 2 dimensões(0 e 1), e a soma for feita nas duas dimensões, \n",
    "                               #o resultado será um escalar. Caso a soma seja realizada em um numero de dimensões menor que o numero de dimensoes\n",
    "                               #do tensor, então o resultado final não será escalar. Pode ser um vetor, uma matriz, ou um tensor de 3 ou mais dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c37193d-7f01-4cb7-bf92-61a46b0b8da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]],\n",
       " \n",
       "         [[3., 2., 3.],\n",
       "          [5., 4., 5.]],\n",
       " \n",
       "         [[6., 7., 6.],\n",
       "          [8., 9., 8.]]]),\n",
       " torch.Size([4, 2, 3]),\n",
       " tensor([44., 44., 44.]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]],[[3.0,2.0,3.0],[5.0,4.0,5.0]],[[6.0,7.0,6.0],[8.0,9.0,8.0]]])\n",
    "x, x.shape, x.sum([0,1]), x.sum([0,1]).shape\n",
    "\n",
    "#neste caso, o tensor é 3D e a soma é realizada em duas dimensões (0 e 1). O resultado final tem o numero de dimensões da quantidade de dimensoes que nao\n",
    "#foi incorporada no somatorio. Além disso, o numero de elementos no resultado final será igual ao tamanho da dimensão que naõ entrou na soma.\n",
    "#Ou seja, resultado final tem uma dimensão -> apenas uma dimensão (2) nao foi usada na soma. Resultado final tem 3 elementos -> dimensão 2 tem tamanho 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cc86a5d-f632-407d-8ed3-bed466460204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0,  1,  2],\n",
       "           [ 3,  4,  5]],\n",
       " \n",
       "          [[ 6,  7,  8],\n",
       "           [ 9, 10, 11]],\n",
       " \n",
       "          [[12, 13, 14],\n",
       "           [15, 16, 17]]],\n",
       " \n",
       " \n",
       "         [[[18, 19, 20],\n",
       "           [21, 22, 23]],\n",
       " \n",
       "          [[24, 25, 26],\n",
       "           [27, 28, 29]],\n",
       " \n",
       "          [[30, 31, 32],\n",
       "           [33, 34, 35]]]]),\n",
       " torch.Size([2, 3, 2, 3]),\n",
       " tensor([[ 90,  96, 102],\n",
       "         [108, 114, 120]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(36).reshape(2, 3, 2, 3)\n",
    "x, x.shape, x.sum([0,1]), x.sum([0,1]).shape\n",
    "\n",
    "#neste caso, tensor tem 4 dimensões, e a soma foi feita ao longo de duas (0 e 1). Resultado final tem duas dimensões (tensor 2D), pois duas dimensões não \n",
    "#foram usadas na soma. ALém disso, resultado final tem 6 elementos pois uma das dimensões nao usadas tem 2 elementos e a outra tem 3 (2*3=6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c1d0214-a1d9-4013-9353-75fc66fcdfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()  #calculo da media de um tensor. divide the sum by the total number of elements\n",
    "                               #A.numel returns the total number of elements in the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54102739-5ddd-48a6-a588-50ad39ebf210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " 2,\n",
       " tensor([3., 5., 7.]),\n",
       " tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0] #também é possível tirar a média de uma dimensão específica. Note que a soma é feita ao longo de uma \n",
    "                                           #unica dimensão e a divisão também é feita pelo número de elementos da mesma dimensão\n",
    "A, A.shape[0], A.sum(axis=0), A.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e98fe850-f668-4d89-af7e-156737fab4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True) #keepdims mantém o número total de dimensões inalterado. Ou seja, A tinha 2 dimensões (0 e 1),\n",
    "                                     # e após a soma, o resultado ainda possui essa configuração. Se não usar keepdims, o resultado\n",
    "                                     # fica com apenas uma dimensão ([3., 12.]). Resumidamente, o tensor resultante tem a mesma forma.\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06938157-c247-4344-b567-37357ac681bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since sum_A keeps its two axes after summing each row, we can divide A by sum_A with broadcasting to create a matrix \n",
    "#where each row sums up to 1\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52f7419a-65f4-4039-b40a-18a4eacbe343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0) #esta função dá a soma cumulativa ao longo de alguma das dimensões. Neste caso, a primeira iteração do somatório\n",
    "                 #inclui apenas os elementos da primeira linha, portanto, os resultados serão 0., 1., e 2.\n",
    "                 #A segunda iteração já soma os valores da segunda linha aos valores calculados anteriormente: \n",
    "                 #0. + 3.= 3. | 1. + 4. = 5. | 2. + 5. = 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4db25092-87ce-460c-b70d-879f4d733ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float)\n",
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y) #torch.dot calcula o produto interno de x e y, ou seja, (0*1) + (1*1) + (2*1) = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346ced00-ee8f-4dc4-9fc9-d2fc3eafbff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternativamente, é possível calcular o produto interno \"manualmente\" fazendo a multiplicação seguida por uma soma:\n",
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33c4d43d-1bef-4740-b7d1-1e40ab190550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([0., 1., 2.]),\n",
       " torch.Size([2, 3]),\n",
       " torch.Size([3]),\n",
       " tensor([ 5., 14.]),\n",
       " tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x, A.shape, x.shape, torch.mv(A, x), A@x #torch.mv = multiplicação de matriz e vetor. @ é inteligente e serve tanto para\n",
    "                                            #multiplicação matriz-vetor ou matriz-matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc773fab-2542-42c7-b8bc-d7813e1d9223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "A, B, torch.mm(A, B), A@B #torch.mm = multiplicação de matrizes\n",
    "#multiplica linha de A com coluna de B e soma o resultado. Depois multiplica a proxima linha de A com a mesma coluna e soma. \n",
    "#Depois repete tudo com a proxima coluna de B e assim por diante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a36650d-d181-4693-a241-f8d01060ad32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), 5.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "#The Euclidean norm that we all learned in elementary school geometry when calculating the \n",
    "#hypotenuse of a right triangle is the square root of the sum of squares of a vector’s elements. \n",
    "#Formally, this is called the l2 norm.\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u), math.sqrt(3.0**2 + (-4.0)**2) #torch.norm calula a norma de um tensor. Note que a resultado de math nao retorna um tensor,\n",
    "                                             #até pq precisa receber números como input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30e98033-b021-49f6-9773-0b8c74a272bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The l1 norm is also common and the associated measure is called the Manhattan distance. By definition, the \n",
    "#l1 norm sums the absolute values of a vector’s elements. Compared to the l2, it is less sensitive to outliers\n",
    "#To compute the l1 norm, we compose the absolute value with the sum operation:\n",
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dac27893-8c29-4b66-b402-848ff524e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tanto as normas l1 quanto l2 são casos especiais da regra geral de normas lp: (SUM_i=1^n{|x_i|^p})^1/p\n",
    "#note que se p=1, se torna a norma l1, e se p=2 se torna a norma l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f7e9911-2231-4d85-a757-1131f3ec4777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Existe também a norma espectral e a norma de Frobenius. A de Frobenius é como se fosse uma l2 de um vetor com forma de matriz.\n",
    "#É dada pela raiz quadrada do somatorio dos quadrados dos elementos de uma matriz.\n",
    "torch.norm(torch.ones((4, 9))) #note que a função usada é igual a da l2 anterior, mas possui linhas e colunas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
