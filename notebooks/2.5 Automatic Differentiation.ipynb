{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0acb09-a37c-42ba-9a2b-482f1b8abae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbe1828-d98c-4b73-945b-ab7020bd0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also create x = torch.arange(4.0, requires_grad=True)\n",
    "x.requires_grad_(True)\n",
    "x.grad  # Initially, the gradient is None by default. Only after running 'y.backward()' below it will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab4c735-be3a-4973-a3a7-a68f91571324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc6d093-1414-401b-b953-2e5bda7cefa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad\n",
    "#O parâmetro requires_grad=True serve para dizer ao PyTorch que ele deve acompanhar as operações realizadas no tensor x, construindo um grafo\n",
    "#computacional que será usado para calcular os gradientes. Quando você chama y.backward(), o PyTorch percorre esse grafo e calcula as derivadas\n",
    "#parciais de y em relação a todos os tensores que foram marcados com requires_grad=True (no caso, o tensor x).\n",
    "#Se x não tivesse requires_grad=True, o PyTorch não rastrearia as operações realizadas com x e, consequentemente, não calcularia\n",
    "#nem armazenaria o gradiente para x.\n",
    "#Portanto, ao definir x=torch.arange(4.0) com requires_grad=True, você está dizendo que deseja que x seja um parâmetro\n",
    "#\"diferenciável\", e é por isso que o y.backward() utiliza esse tensor para calcular e armazenar o gradiente em x.grad.\n",
    "#Além disso, O atributo grad_fn=<MulBackward0> indica que o tensor foi criado a partir de uma operação diferenciável\n",
    "#(neste caso, uma multiplicação) e que possui uma função associada para calcular o gradiente durante o processo de backpropagation.\n",
    "#Ou seja, grad_fn: É um atributo interno que aponta para a \"função de retropropagação\" (backward function) que foi utilizada para gerar aquele tensor.\n",
    "#E <MulBackward0>: Especifica que a operação que produziu o tensor foi uma multiplicação. Essa função será chamada quando você executar y.backward(),\n",
    "#permitindo que o PyTorch calcule como cada operação (neste caso, a multiplicação) contribui para o gradiente final.\n",
    "#Portanto, mesmo que o resultado numérico seja 28, o PyTorch mantém o histórico das operações (a árvore computacional) e, ao ver grad_fn=<MulBackward0>,\n",
    "#sabe exatamente qual função usar para propagar o gradiente através dessa multiplicação.\n",
    "#Caso requires_grad=True não tivesse sido utilizado, as operações não seriam rastreadas, x.grad não retornaria resultado, e o atributo grad_fn=<MulBackward0>\n",
    "#não estaráia presente no resultado do cálculo de y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3431ed1f-1333-4189-9ace-90e986340430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x #lembre que x.grad retorna o gradiente >de y< \n",
    "#o produto interno de dois vetores( torch.dot(x, x) ) é igual à norma desse vetor ao quadrado. O gradiente desta norma ao quadrado\n",
    "#é igual a duas vezes este vetor. Portanto, 2 * torch.dot(x, x) == 4*x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105d2dd3-ee00-4175-b50a-fd058fe81bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6., grad_fn=<SumBackward0>), tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()  # Reseta os valores do gradiente de y que haviam sido armazenados com x.requires_grad_(True) após rodar y.backward()\n",
    "y = x.sum() #y agora é a função do somatório de todos os elementos do vetor x\n",
    "y.backward() #calcula o gradiente de y em relação a x (em relação aos x_0, x_1, x_2 e x_3 presente em x)\n",
    "y, x.grad # resultado da função y quando x=tensor([0., 1., 2., 3.]), e gradiente de y para valores de x\n",
    "          #note que a derivada em relação a x_0 de x_0 é 1, de x_1 em relação a x_1 é 1, e assim por diante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b29b7e-420e-4d5e-b119-b66196121e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x \n",
    "y #agora, y não é mais um esvalar, e sim um vetor. Quando y, é vetor, y.backward() retorna erro. Para usá-lo, precisa transformá-lo em escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8ff8f3-648b-4d71-99fc-f26fb763049f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(gradient=torch.ones(len(y)))  #Faster: y.sum().backward() #gradient=torch.ones(len(y)) transforma y em um escalar l\n",
    "                                         #fazendo o produto interno entre y e um vetor v feito de uns (1). O gradiente é calculado\n",
    "                                         #a partir deste resultado l\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31c3c52-667d-4463-a9df-948f22715684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you simply calculate z and then z.backward(), PyTorch's automatic differentiation will trace back all dependencies to find the gradient\n",
    "#of z with respect to x.  This gradient will reflect both the direct effect of x on z and the indirect effect channeled through y.\n",
    "#Mathematically, using the chain rule, the total derivative dz/dx would consider both paths.\n",
    "\n",
    "#you might want to know: \"If I change x slightly, how much does z change directly, holding the value of y effectively constant at its current value?\"\n",
    "#This is where \"detaching\" comes in.  You want to treat y (or a value derived from y) as if it were a constant with respect to x when calculating\n",
    "#the gradient of z with respect to x.\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "\n",
    "#Assume we want to calculate z = y * x\n",
    "\n",
    "u = y.detach() #This is the crucial step. detach() does the following: Creates a new tensor u: u will have the same numerical value as y at the moment\n",
    "               #of detachment. Breaks the computation graph link: Crucially, u is no longer considered part of the computational path that leads back\n",
    "               #to x for gradient calculation. PyTorch \"forgets\" how u was derived from y and, ultimately, from x. u is treated as a constant with respect\n",
    "               #to x in the backward pass.\n",
    "z = u * x #Now, z is computed using x and the detached u, which will be treated as a constant\n",
    "z.sum().backward() #Using basic calculus, the derivative of x * u with respect to x (where u is constant) is simply u (d/dx ux = u). \n",
    "x.grad == u #Remember that x.grad contains the stored result of the gradient calculated with z.sum().backward(), which is equal to\n",
    "#z.backward(gradient=torch.ones(len(z))). And this gradient is, as shown above, d/dx ux = u. Therefore, x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc75a7c-e43e-47ce-8371-767ede04e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that while this procedure detaches y’s ancestors from the graph leading to z, the computational graph leading to y persists and thus we\n",
    "#can calculate the gradient of y with respect to x. Como y = x^2, então d/dx y = 2x\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9667c1c0-4f1e-4a8a-b138-22e66f77e292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "#A função acima retorna um valor linear para um valor de a. Ao tirar o gradiente de uma função linear, ele será igual ao resultado da função dividido pelo\n",
    "#pelo próprio a. Por exemplo, se def f(a) retornasse 5*a, o grad em função de a é d/da 5a = 5. Se dividirmos 5a por a, também teremos 5.\n",
    "\n",
    "a = torch.randn(size=(), requires_grad=True) #size=() gera um tensor de dimensão 0, ou seja, um escalar\n",
    "d = f(a)\n",
    "d.backward()\n",
    "a.grad == d / a # portanto, se d = f(a), então a.grad é igual a d/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7f95f-d955-457b-945e-511a5dabcad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
